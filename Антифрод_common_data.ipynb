{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Антифрод common_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKChL9cGbNrq",
        "outputId": "ae0c238e-d96c-4382-b870-307275861e69"
      },
      "source": [
        "!pip install pymorphy2\n",
        "!pip install jsonlines"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.15.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYnqAgk8eAHy",
        "outputId": "cd82ba35-9424-45f0-adaa-fc6d30e4276f"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import pymorphy2\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import jsonlines\n",
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from gensim.models import word2vec\n",
        "import numpy as np\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "stops = set(stopwords.words(\"english\")) | set(stopwords.words(\"russian\"))\n",
        "def review_to_wordlist(review):\n",
        "    #1)\n",
        "    review_text = re.sub(\"[^а-яА-Яa-zA-Z1-9]\",\" \", review)\n",
        "    #2)\n",
        "    words = review_text.lower().split()\n",
        "    #3)\n",
        "    words = [w for w in words if not w in stops]\n",
        "    #4)\n",
        "    words = [morph.parse(w)[0].normal_form for w in words ]\n",
        "    return(words)\n",
        "\n",
        "def clear_text(review):\n",
        "    #1)\n",
        "    review_text = re.sub(\"[^а-яА-Яa-zA-Z1-9]\",\" \", review)\n",
        "    #2)\n",
        "    words = review_text.split()\n",
        "    #3)\n",
        "    #words = [w for w in words if not w in stops]\n",
        "    #4)\n",
        "    #words = [morph.parse(w)[0].normal_form for w in words ]\n",
        "    return(\" \".join(words))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnV31gjjoyf-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7ygNaoGeFl6"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/commondata_form_data (5).csv\")"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "7ydtdvMGfr3h",
        "outputId": "0304a58c-9d2a-47ce-b2d0-36e815e4babc"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>type</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Отчетство</td>\n",
              "      <td>ShortText</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Сколько ву вас сотрудников?</td>\n",
              "      <td>ShortText</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Часто ли вы планируете, как будете себя вести ...</td>\n",
              "      <td>OneChoice</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Какого литературного героя вы хотели бы встрет...</td>\n",
              "      <td>ShortText</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Вам легко найти общий язык с незнакомыми людьми?</td>\n",
              "      <td>OneChoice</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question       type  status\n",
              "0                                          Отчетство  ShortText       1\n",
              "1                       Сколько ву вас сотрудников?   ShortText       0\n",
              "2  Часто ли вы планируете, как будете себя вести ...  OneChoice       0\n",
              "3  Какого литературного героя вы хотели бы встрет...  ShortText       0\n",
              "4   Вам легко найти общий язык с незнакомыми людьми?  OneChoice       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyA5A4F7hptg",
        "outputId": "607ce624-ccb3-4bee-c5a4-6eab1b1db917"
      },
      "source": [
        "data[\"type\"].unique()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['OneChoice', 'ShortText', 'MultipleChoice'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfcNsDPNg3VU"
      },
      "source": [
        "#ShortText - 0\n",
        "#OneChoice - 1\n",
        "#MultipleChoice - 2\n",
        "def type_to_encode(type_data: str) -> int:\n",
        "    if type_data == \"ShortText\":\n",
        "        return 0\n",
        "    if type_data == \"OneChoice\":\n",
        "        return 1\n",
        "    if type_data == \"MultipleChoice\":\n",
        "        return 2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y55ntbrPfs-D"
      },
      "source": [
        "data[\"question_clear\"] = data[\"question\"].apply(review_to_wordlist)\n",
        "data[\"type_encoded\"] = data[\"type\"].apply(type_to_encode)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "SValL7-zh9K1",
        "outputId": "16a73f02-c346-4f9c-eaf3-4573c4bd53de"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>type</th>\n",
              "      <th>status</th>\n",
              "      <th>question_clear</th>\n",
              "      <th>type_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Отчетство</td>\n",
              "      <td>ShortText</td>\n",
              "      <td>1</td>\n",
              "      <td>[отчетство]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Сколько ву вас сотрудников?</td>\n",
              "      <td>ShortText</td>\n",
              "      <td>0</td>\n",
              "      <td>[сколько, ву, сотрудник]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Часто ли вы планируете, как будете себя вести ...</td>\n",
              "      <td>OneChoice</td>\n",
              "      <td>0</td>\n",
              "      <td>[часто, планировать, быть, вести, встреча, бес...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Какого литературного героя вы хотели бы встрет...</td>\n",
              "      <td>ShortText</td>\n",
              "      <td>0</td>\n",
              "      <td>[какой, литературный, герой, хотеть, встретить...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Вам легко найти общий язык с незнакомыми людьми?</td>\n",
              "      <td>OneChoice</td>\n",
              "      <td>0</td>\n",
              "      <td>[легко, найти, общий, язык, незнакомый, человек]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ... type_encoded\n",
              "0                                          Отчетство  ...            0\n",
              "1                       Сколько ву вас сотрудников?   ...            0\n",
              "2  Часто ли вы планируете, как будете себя вести ...  ...            1\n",
              "3  Какого литературного героя вы хотели бы встрет...  ...            0\n",
              "4   Вам легко найти общий язык с незнакомыми людьми?  ...            1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kSEqMKriAlh"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(data['question_clear'], size=300, window=3, workers=4)\n",
        "#создадим словарь со словами и соответсвующими им векторами\n",
        "w2v = dict(zip(model.wv.index2word, model.wv.vectors))"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXOZIYMpLnnU"
      },
      "source": [
        "model.save('w2v')"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViyZLiUPL7ln"
      },
      "source": [
        " from gensim.models import word2vec\n",
        " model = word2vec.Word2Vec.load('w2v')\n",
        " w2v = dict(zip(model.wv.index2word, model.wv.vectors))\n",
        " w2v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlAA533TjHo2"
      },
      "source": [
        "class mean_vectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        self.dim = len(next(iter(w2v.values())))\n",
        "\n",
        "    def fit(self, X):\n",
        "        return self \n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHk-kEebjOrY",
        "outputId": "942e7e54-c422-421a-a215-06cfa84a1f09"
      },
      "source": [
        "data_mean=mean_vectorizer(w2v).fit(data['question_clear']).transform(data['question_clear'])\n",
        "data_mean = np.concatenate((np.array([[i] for i in data['type_encoded']]), data_mean), axis=1)\n",
        "data_mean.shape"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(366, 301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5Dqc3y21mN7",
        "outputId": "5a347d46-a376-45f5-d4a4-733811f215f7"
      },
      "source": [
        "data_0_mean=mean_vectorizer(w2v).fit([data['question_clear'][1]]).transform([data['question_clear'][1]])\n",
        "data_0_mean = np.concatenate((np.array([[data['type_encoded'][1]]]), data_0_mean), axis=1)\n",
        "data_0_mean.shape"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnlkfoWU13h3",
        "outputId": "03565260-a1d7-45e8-df52-faba8360f10a"
      },
      "source": [
        "estimator.predict(data_0_mean)[0][0]"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc8ZiK9YjT5v",
        "outputId": "2f3207aa-674a-444e-c951-3614d9ce7d57"
      },
      "source": [
        "def split(train,y,ratio):\n",
        "    idx = round(train.shape[0] * ratio)\n",
        "    return train[:idx, :], train[idx:, :], y[:idx], y[idx:]\n",
        "y = data['status']\n",
        "Xtr, Xval, ytr, yval = split(data_mean, y,0.8)\n",
        "Xtr.shape,Xval.shape,ytr.mean(),yval.mean()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((293, 301), (73, 301), 0.3651877133105802, 0.2465753424657534)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q1jlivopAN0",
        "outputId": "97934f1d-019a-43c7-b31a-edcc3eb714c1"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import regularizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, input_dim=Xtr.shape[1], activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "    return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=baseline_model,epochs=50, nb_epoch=40, batch_size=64,validation_data=(Xval, yval), verbose=2)\n",
        "estimator.fit(Xtr, ytr)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 - 0s - loss: 0.6930 - accuracy: 0.5563 - f1_m: 0.1172 - precision_m: 0.1167 - recall_m: 0.1795 - val_loss: 0.6895 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 - 0s - loss: 0.6871 - accuracy: 0.6348 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6606 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 - 0s - loss: 0.6531 - accuracy: 0.6348 - f1_m: 0.0174 - precision_m: 0.2000 - recall_m: 0.0091 - val_loss: 0.5069 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 - 0s - loss: 0.5748 - accuracy: 0.6348 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.4139 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 - 0s - loss: 0.5511 - accuracy: 0.6348 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.4273 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 - 0s - loss: 0.5313 - accuracy: 0.6348 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.4456 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 - 0s - loss: 0.5547 - accuracy: 0.6348 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.4214 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 - 0s - loss: 0.5347 - accuracy: 0.6348 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.4223 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 - 0s - loss: 0.5031 - accuracy: 0.6348 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.4193 - val_accuracy: 0.7534 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 - 0s - loss: 0.5332 - accuracy: 0.6724 - f1_m: 0.2958 - precision_m: 0.6921 - recall_m: 0.2042 - val_loss: 0.4146 - val_accuracy: 0.7534 - val_f1_m: 0.6515 - val_precision_m: 0.5000 - val_recall_m: 0.9375\n",
            "Epoch 11/50\n",
            "5/5 - 0s - loss: 0.5319 - accuracy: 0.6792 - f1_m: 0.5185 - precision_m: 0.5933 - recall_m: 0.4791 - val_loss: 0.4249 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 12/50\n",
            "5/5 - 0s - loss: 0.5193 - accuracy: 0.7270 - f1_m: 0.6776 - precision_m: 0.5988 - recall_m: 0.8125 - val_loss: 0.4298 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 13/50\n",
            "5/5 - 0s - loss: 0.5371 - accuracy: 0.7611 - f1_m: 0.7149 - precision_m: 0.6132 - recall_m: 0.8682 - val_loss: 0.4201 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 14/50\n",
            "5/5 - 0s - loss: 0.5006 - accuracy: 0.7577 - f1_m: 0.7351 - precision_m: 0.6230 - recall_m: 0.9072 - val_loss: 0.4308 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 15/50\n",
            "5/5 - 0s - loss: 0.5265 - accuracy: 0.7509 - f1_m: 0.7183 - precision_m: 0.5974 - recall_m: 0.9127 - val_loss: 0.4387 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 16/50\n",
            "5/5 - 0s - loss: 0.5146 - accuracy: 0.7474 - f1_m: 0.7092 - precision_m: 0.5980 - recall_m: 0.8791 - val_loss: 0.4124 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 17/50\n",
            "5/5 - 0s - loss: 0.4858 - accuracy: 0.7577 - f1_m: 0.7207 - precision_m: 0.6070 - recall_m: 0.8995 - val_loss: 0.4081 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 18/50\n",
            "5/5 - 0s - loss: 0.4919 - accuracy: 0.7850 - f1_m: 0.7192 - precision_m: 0.6699 - recall_m: 0.8039 - val_loss: 0.3975 - val_accuracy: 0.8356 - val_f1_m: 0.2917 - val_precision_m: 0.4375 - val_recall_m: 0.2188\n",
            "Epoch 19/50\n",
            "5/5 - 0s - loss: 0.4953 - accuracy: 0.7611 - f1_m: 0.6427 - precision_m: 0.7392 - recall_m: 0.6344 - val_loss: 0.4395 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 20/50\n",
            "5/5 - 0s - loss: 0.5176 - accuracy: 0.7509 - f1_m: 0.7312 - precision_m: 0.6154 - recall_m: 0.9056 - val_loss: 0.4263 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 21/50\n",
            "5/5 - 0s - loss: 0.5076 - accuracy: 0.7474 - f1_m: 0.7139 - precision_m: 0.5989 - recall_m: 0.8919 - val_loss: 0.4084 - val_accuracy: 0.7671 - val_f1_m: 0.6667 - val_precision_m: 0.5086 - val_recall_m: 0.9688\n",
            "Epoch 22/50\n",
            "5/5 - 0s - loss: 0.4959 - accuracy: 0.7543 - f1_m: 0.7334 - precision_m: 0.6216 - recall_m: 0.9077 - val_loss: 0.4059 - val_accuracy: 0.7808 - val_f1_m: 0.5556 - val_precision_m: 0.5250 - val_recall_m: 0.5938\n",
            "Epoch 23/50\n",
            "5/5 - 0s - loss: 0.4995 - accuracy: 0.8191 - f1_m: 0.7471 - precision_m: 0.7703 - recall_m: 0.7353 - val_loss: 0.4153 - val_accuracy: 0.7671 - val_f1_m: 0.5473 - val_precision_m: 0.5119 - val_recall_m: 0.5938\n",
            "Epoch 24/50\n",
            "5/5 - 0s - loss: 0.4880 - accuracy: 0.8055 - f1_m: 0.7647 - precision_m: 0.6770 - recall_m: 0.8842 - val_loss: 0.3912 - val_accuracy: 0.8219 - val_f1_m: 0.6026 - val_precision_m: 0.8500 - val_recall_m: 0.4688\n",
            "Epoch 25/50\n",
            "5/5 - 0s - loss: 0.4769 - accuracy: 0.8191 - f1_m: 0.7375 - precision_m: 0.7192 - recall_m: 0.7970 - val_loss: 0.4055 - val_accuracy: 0.7808 - val_f1_m: 0.5556 - val_precision_m: 0.5250 - val_recall_m: 0.5938\n",
            "Epoch 26/50\n",
            "5/5 - 0s - loss: 0.4482 - accuracy: 0.8020 - f1_m: 0.6657 - precision_m: 0.7774 - recall_m: 0.6101 - val_loss: 0.3746 - val_accuracy: 0.8219 - val_f1_m: 0.2800 - val_precision_m: 0.3889 - val_recall_m: 0.2188\n",
            "Epoch 27/50\n",
            "5/5 - 0s - loss: 0.4235 - accuracy: 0.8225 - f1_m: 0.7280 - precision_m: 0.8322 - recall_m: 0.6502 - val_loss: 0.4041 - val_accuracy: 0.7945 - val_f1_m: 0.6146 - val_precision_m: 0.7812 - val_recall_m: 0.5312\n",
            "Epoch 28/50\n",
            "5/5 - 0s - loss: 0.4252 - accuracy: 0.8362 - f1_m: 0.7525 - precision_m: 0.8160 - recall_m: 0.7107 - val_loss: 0.3861 - val_accuracy: 0.8082 - val_f1_m: 0.2692 - val_precision_m: 0.3500 - val_recall_m: 0.2188\n",
            "Epoch 29/50\n",
            "5/5 - 0s - loss: 0.3860 - accuracy: 0.8669 - f1_m: 0.8128 - precision_m: 0.8830 - recall_m: 0.7615 - val_loss: 0.3919 - val_accuracy: 0.8082 - val_f1_m: 0.2692 - val_precision_m: 0.3500 - val_recall_m: 0.2188\n",
            "Epoch 30/50\n",
            "5/5 - 0s - loss: 0.4876 - accuracy: 0.8123 - f1_m: 0.7401 - precision_m: 0.7795 - recall_m: 0.7580 - val_loss: 0.3955 - val_accuracy: 0.8082 - val_f1_m: 0.2273 - val_precision_m: 0.4167 - val_recall_m: 0.1562\n",
            "Epoch 31/50\n",
            "5/5 - 0s - loss: 0.5160 - accuracy: 0.7304 - f1_m: 0.4509 - precision_m: 0.9418 - recall_m: 0.3341 - val_loss: 0.4213 - val_accuracy: 0.8082 - val_f1_m: 0.2692 - val_precision_m: 0.3500 - val_recall_m: 0.2188\n",
            "Epoch 32/50\n",
            "5/5 - 0s - loss: 0.4629 - accuracy: 0.8225 - f1_m: 0.7522 - precision_m: 0.7117 - recall_m: 0.8274 - val_loss: 0.4513 - val_accuracy: 0.7671 - val_f1_m: 0.7000 - val_precision_m: 0.5833 - val_recall_m: 0.8750\n",
            "Epoch 33/50\n",
            "5/5 - 0s - loss: 0.4134 - accuracy: 0.8430 - f1_m: 0.7864 - precision_m: 0.8395 - recall_m: 0.7718 - val_loss: 0.3870 - val_accuracy: 0.8219 - val_f1_m: 0.2800 - val_precision_m: 0.3889 - val_recall_m: 0.2188\n",
            "Epoch 34/50\n",
            "5/5 - 0s - loss: 0.4125 - accuracy: 0.8669 - f1_m: 0.7958 - precision_m: 0.9058 - recall_m: 0.7165 - val_loss: 0.3804 - val_accuracy: 0.8356 - val_f1_m: 0.6029 - val_precision_m: 0.5833 - val_recall_m: 0.6250\n",
            "Epoch 35/50\n",
            "5/5 - 0s - loss: 0.3852 - accuracy: 0.8635 - f1_m: 0.8147 - precision_m: 0.8385 - recall_m: 0.7975 - val_loss: 0.3958 - val_accuracy: 0.8493 - val_f1_m: 0.6667 - val_precision_m: 0.8571 - val_recall_m: 0.5625\n",
            "Epoch 36/50\n",
            "5/5 - 0s - loss: 0.3775 - accuracy: 0.8635 - f1_m: 0.7913 - precision_m: 0.9089 - recall_m: 0.7361 - val_loss: 0.4074 - val_accuracy: 0.8356 - val_f1_m: 0.6437 - val_precision_m: 0.8462 - val_recall_m: 0.5312\n",
            "Epoch 37/50\n",
            "5/5 - 0s - loss: 0.3659 - accuracy: 0.8805 - f1_m: 0.8365 - precision_m: 0.8551 - recall_m: 0.8292 - val_loss: 0.4177 - val_accuracy: 0.8219 - val_f1_m: 0.2800 - val_precision_m: 0.3889 - val_recall_m: 0.2188\n",
            "Epoch 38/50\n",
            "5/5 - 0s - loss: 0.3945 - accuracy: 0.8123 - f1_m: 0.6730 - precision_m: 0.9351 - recall_m: 0.5363 - val_loss: 0.4663 - val_accuracy: 0.8493 - val_f1_m: 0.6667 - val_precision_m: 0.8571 - val_recall_m: 0.5625\n",
            "Epoch 39/50\n",
            "5/5 - 0s - loss: 0.4379 - accuracy: 0.8635 - f1_m: 0.8251 - precision_m: 0.8006 - recall_m: 0.8656 - val_loss: 0.4149 - val_accuracy: 0.8356 - val_f1_m: 0.6296 - val_precision_m: 0.8636 - val_recall_m: 0.5000\n",
            "Epoch 40/50\n",
            "5/5 - 0s - loss: 0.3878 - accuracy: 0.8328 - f1_m: 0.7203 - precision_m: 0.9335 - recall_m: 0.5958 - val_loss: 0.3963 - val_accuracy: 0.8356 - val_f1_m: 0.6296 - val_precision_m: 0.8636 - val_recall_m: 0.5000\n",
            "Epoch 41/50\n",
            "5/5 - 0s - loss: 0.3396 - accuracy: 0.8840 - f1_m: 0.8383 - precision_m: 0.8571 - recall_m: 0.8266 - val_loss: 0.4674 - val_accuracy: 0.7671 - val_f1_m: 0.5577 - val_precision_m: 0.5109 - val_recall_m: 0.6250\n",
            "Epoch 42/50\n",
            "5/5 - 0s - loss: 0.3480 - accuracy: 0.8737 - f1_m: 0.8222 - precision_m: 0.8282 - recall_m: 0.8277 - val_loss: 0.4075 - val_accuracy: 0.8356 - val_f1_m: 0.3077 - val_precision_m: 0.4000 - val_recall_m: 0.2500\n",
            "Epoch 43/50\n",
            "5/5 - 0s - loss: 0.3676 - accuracy: 0.8532 - f1_m: 0.7635 - precision_m: 0.9352 - recall_m: 0.6499 - val_loss: 0.4408 - val_accuracy: 0.8219 - val_f1_m: 0.6190 - val_precision_m: 0.8333 - val_recall_m: 0.5000\n",
            "Epoch 44/50\n",
            "5/5 - 0s - loss: 0.3210 - accuracy: 0.8737 - f1_m: 0.8319 - precision_m: 0.8176 - recall_m: 0.8556 - val_loss: 0.4468 - val_accuracy: 0.8493 - val_f1_m: 0.6667 - val_precision_m: 0.8571 - val_recall_m: 0.5625\n",
            "Epoch 45/50\n",
            "5/5 - 0s - loss: 0.3219 - accuracy: 0.8805 - f1_m: 0.8092 - precision_m: 0.9250 - recall_m: 0.7228 - val_loss: 0.4750 - val_accuracy: 0.8219 - val_f1_m: 0.2963 - val_precision_m: 0.3636 - val_recall_m: 0.2500\n",
            "Epoch 46/50\n",
            "5/5 - 0s - loss: 0.3043 - accuracy: 0.8805 - f1_m: 0.8119 - precision_m: 0.9176 - recall_m: 0.7360 - val_loss: 0.5744 - val_accuracy: 0.7945 - val_f1_m: 0.5743 - val_precision_m: 0.5357 - val_recall_m: 0.6250\n",
            "Epoch 47/50\n",
            "5/5 - 0s - loss: 0.3314 - accuracy: 0.8669 - f1_m: 0.8153 - precision_m: 0.8209 - recall_m: 0.8388 - val_loss: 0.4810 - val_accuracy: 0.8082 - val_f1_m: 0.2692 - val_precision_m: 0.3500 - val_recall_m: 0.2188\n",
            "Epoch 48/50\n",
            "5/5 - 0s - loss: 0.3295 - accuracy: 0.8737 - f1_m: 0.7794 - precision_m: 0.9778 - recall_m: 0.6528 - val_loss: 0.5038 - val_accuracy: 0.8493 - val_f1_m: 0.6667 - val_precision_m: 0.8571 - val_recall_m: 0.5625\n",
            "Epoch 49/50\n",
            "5/5 - 0s - loss: 0.2967 - accuracy: 0.8908 - f1_m: 0.8489 - precision_m: 0.8661 - recall_m: 0.8356 - val_loss: 0.4837 - val_accuracy: 0.8356 - val_f1_m: 0.6029 - val_precision_m: 0.5833 - val_recall_m: 0.6250\n",
            "Epoch 50/50\n",
            "5/5 - 0s - loss: 0.3254 - accuracy: 0.8771 - f1_m: 0.8137 - precision_m: 0.8665 - recall_m: 0.7711 - val_loss: 0.4985 - val_accuracy: 0.8356 - val_f1_m: 0.6296 - val_precision_m: 0.8636 - val_recall_m: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff4851f21d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju7esvVz62ef",
        "outputId": "1453f699-4290-4692-dea4-4766ea4d010c"
      },
      "source": [
        "estimator.model.save('model')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Wy9Ytq-2Xr"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/model/', custom_objects={\"f1_m\": f1_m, \n",
        "                                                                   \"precision_m\": precision_m, \n",
        "                                                                   \"recall_m\": recall_m})"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV_D7YuAv7pB"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import pymorphy2\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import jsonlines\n",
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from gensim.models import word2vec\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import regularizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "stops = set(stopwords.words(\"english\")) | set(stopwords.words(\"russian\"))\n",
        "def review_to_wordlist(review: str) -> list:\n",
        "    #1)\n",
        "    review_text = re.sub(\"[^а-яА-Яa-zA-Z1-9]\",\" \", review)\n",
        "    #2)\n",
        "    words = review_text.lower().split()\n",
        "    #3)\n",
        "    words = [w for w in words if not w in stops]\n",
        "    #4)\n",
        "    words = [morph.parse(w)[0].normal_form for w in words ]\n",
        "    return(words)\n",
        "\n",
        "def type_to_encode(type_data: str) -> int:\n",
        "    if type_data == \"ShortText\":\n",
        "        return 0\n",
        "    if type_data == \"OneChoice\":\n",
        "        return 1\n",
        "    if type_data == \"MultipleChoice\":\n",
        "        return 2\n",
        "\n",
        "class mean_vectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        self.dim = len(next(iter(w2v.values())))\n",
        "\n",
        "    def fit(self, X):\n",
        "        return self \n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])\n",
        "\n",
        "def check_is_private(question: str, question_type: str) -> int:\n",
        "    encoded_text = review_to_wordlist(question)\n",
        "    encoded_type = type_to_encode(question_type)\n",
        "\n",
        "    model = word2vec.Word2Vec.load('w2v')\n",
        "    w2v = dict(zip(model.wv.index2word, model.wv.vectors))\n",
        "\n",
        "    estimator = keras.models.load_model('model', \n",
        "                                        custom_objects={\"f1_m\": f1_m, \n",
        "                                                        \"precision_m\": precision_m, \n",
        "                                                        \"recall_m\": recall_m})\n",
        "    \n",
        "    data_mean = mean_vectorizer(w2v).fit([encoded_text]).transform([encoded_text])\n",
        "    data_mean = np.concatenate((np.array([[encoded_type]]), data_mean), axis=1)\n",
        "\n",
        "    return estimator.predict(data_mean)[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}